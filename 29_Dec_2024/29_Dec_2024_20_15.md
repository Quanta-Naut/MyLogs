# Workspace File Summary
## Generated On: Sunday, December 29, 2024 at 8:15:11 PM
This summary lists all files in the workspace with brief descriptions.
---
### Project Description
This project appears to be a machine learning project focused on classification algorithms. The goal is likely to compare the performance of various machine learning models on a given dataset. The project involves data preprocessing, model training, and evaluation.

### File Descriptions

#### WorkspaceSummary.md
- **Purpose**: This file likely contains a summary of the workspace, including details about the project structure, key files, and their purposes.
- **Type**: Documentation
- **Usage**: Provides an overview of the project for collaborators or future reference.

#### data_preprossecing.ipynb
- **Purpose**: This Jupyter Notebook file is used for data preprocessing. It likely includes steps such as data cleaning, normalization, and feature engineering.
- **Type**: Code
- **Usage**: Prepares the raw data for model training and evaluation.

#### support_vector_machine.pkl
- **Purpose**: This file contains a trained Support Vector Machine (SVM) model saved using Python's pickle module.
- **Type**: Model
- **Usage**: Used to load the trained SVM model for predictions or further evaluation.

#### random_forest.pkl
- **Purpose**: This file contains a trained Random Forest model saved using Python's pickle module.
- **Type**: Model
- **Usage**: Used to load the trained Random Forest model for predictions or further evaluation.

#### neural_network_(mlp).pkl
- **Purpose**: This file contains a trained Multi-Layer Perceptron (MLP) neural network model saved using Python's pickle module.
- **Type**: Model
- **Usage**: Used to load the trained MLP model for predictions or further evaluation.

#### naive_bayes.pkl
- **Purpose**: This file contains a trained Naive Bayes model saved using Python's pickle module.
- **Type**: Model
- **Usage**: Used to load the trained Naive Bayes model for predictions or further evaluation.

#### logistic_regression.pkl
- **Purpose**: This file contains a trained Logistic Regression model saved using Python's pickle module.
- **Type**: Model
- **Usage**: Used to load the trained Logistic Regression model for predictions or further evaluation.

#### k-nearest_neighbors.pkl
- **Purpose**: This file contains a trained K-Nearest Neighbors (KNN) model saved using Python's pickle module.
- **Type**: Model
- **Usage**: Used to load the trained KNN model for predictions or further evaluation.

#### gradient_boosting.pkl
- **Purpose**: This file contains a trained Gradient Boosting model saved using Python's pickle module.
- **Type**: Model
- **Usage**: Used to load the trained Gradient Boosting model for predictions or further evaluation.

#### decision_tree.pkl
- **Purpose**: This file contains a trained Decision Tree model saved using Python's pickle module.
- **Type**: Model
- **Usage**: Used to load the trained Decision Tree model for predictions or further evaluation.

#### train.csv
- **Purpose**: This CSV file contains the training dataset used to train the machine learning models.
- **Type**: Data
- **Usage**: Used as input data for model training.

#### test.csv
- **Purpose**: This CSV file contains the test dataset used to evaluate the performance of the trained models.
- **Type**: Data
- **Usage**: Used as input data for model evaluation.

#### gender_submission.csv
- **Purpose**: This CSV file likely contains a sample submission file for a gender-based prediction task, possibly related to a Kaggle competition.
- **Type**: Data
- **Usage**: Used as a template for creating submission files for model predictions.

### Learning or Building
This project is primarily focused on building a machine learning project. It involves practical implementation and comparison of various machine learning algorithms, which can also serve as a learning experience for understanding different models and their performance metrics. 
### Project Description:
 The provided code is a machine learning pipeline for the Titanic dataset. It performs data preprocessing, trains multiple models, evaluates their performance, and saves the models. Additionally, it includes functionality to load saved models and make predictions based on user input.

### Statistics:
- **Number of lines:** 179
- **Number of functions:** 2 (`load_models_from_folder`, `get_titanic_input`)
- **Number of classes:** 0
- **Number of imports:** 16
- **Number of models trained:** 8 (SVM, KNN, Decision Tree, Logistic Regression, Random Forest, Gradient Boosting, MLP, Naive Bayes)

### Key Steps:
1. **Data Loading:** Reads training and test data from CSV files.
2. **Data Preprocessing:** Handles missing values and converts categorical variables to numerical.
3. **Feature Selection:** Selects relevant features and scales them.
4. **Model Training:** Trains a logistic regression model and evaluates its performance.
5. **Model Comparison:** Trains multiple models and compares their accuracies.
6. **Model Saving:** Saves trained models to disk.
7. **Model Loading and Prediction:** Loads saved models and makes predictions based on user input.
