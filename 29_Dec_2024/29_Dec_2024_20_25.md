# Tarun's Workspace File Summary
## Generated On: Sunday, December 29, 2024 at 8:25:59 PM
This summary lists all files in the workspace with brief descriptions.
---
### Project Description
This project appears to be a machine learning project focused on classification algorithms. The goal is likely to preprocess data, train various machine learning models, and evaluate their performance. The project involves learning new skills in data preprocessing, model training, and evaluation.

### Relevant Files

#### WorkspaceSummary.md
- **Purpose**: This file likely contains a summary of the workspace, including the structure of the project, descriptions of the files, and possibly instructions on how to run the code.
- **Project Role**: Documentation
- **Learning or Building**: Learning and building

#### data_preprossecing.ipynb
- **Purpose**: This Jupyter Notebook file is used for data preprocessing. It likely contains code for cleaning, transforming, and preparing the dataset for model training.
- **Project Role**: Data preprocessing
- **Learning or Building**: Learning and building

#### support_vector_machine.pkl
- **Purpose**: This file contains a trained Support Vector Machine (SVM) model saved using Python's pickle module.
- **Project Role**: Model storage
- **Learning or Building**: Building

#### random_forest.pkl
- **Purpose**: This file contains a trained Random Forest model saved using Python's pickle module.
- **Project Role**: Model storage
- **Learning or Building**: Building

#### neural_network_(mlp).pkl
- **Purpose**: This file contains a trained Multi-Layer Perceptron (MLP) neural network model saved using Python's pickle module.
- **Project Role**: Model storage
- **Learning or Building**: Building

#### naive_bayes.pkl
- **Purpose**: This file contains a trained Naive Bayes model saved using Python's pickle module.
- **Project Role**: Model storage
- **Learning or Building**: Building

#### logistic_regression.pkl
- **Purpose**: This file contains a trained Logistic Regression model saved using Python's pickle module.
- **Project Role**: Model storage
- **Learning or Building**: Building

#### k-nearest_neighbors.pkl
- **Purpose**: This file contains a trained K-Nearest Neighbors (KNN) model saved using Python's pickle module.
- **Project Role**: Model storage
- **Learning or Building**: Building

#### gradient_boosting.pkl
- **Purpose**: This file contains a trained Gradient Boosting model saved using Python's pickle module.
- **Project Role**: Model storage
- **Learning or Building**: Building

#### decision_tree.pkl
- **Purpose**: This file contains a trained Decision Tree model saved using Python's pickle module.
- **Project Role**: Model storage
- **Learning or Building**: Building

#### train.csv
- **Purpose**: This CSV file contains the training dataset used to train the machine learning models.
- **Project Role**: Dataset
- **Learning or Building**: Learning and building

#### test.csv
- **Purpose**: This CSV file contains the test dataset used to evaluate the performance of the trained models.
- **Project Role**: Dataset
- **Learning or Building**: Learning and building

#### gender_submission.csv
- **Purpose**: This CSV file likely contains sample submission data, possibly for a Kaggle competition, indicating the format required for model predictions.
- **Project Role**: Dataset
- **Learning or Building**: Learning and building 
### Project Description:
 The provided code is a machine learning pipeline for predicting survival on the Titanic dataset. It includes data preprocessing, model training, evaluation, and comparison of multiple models. Here are some statistics about the code:

- **Number of lines**: 157
- **Number of functions**: 2 (`load_models_from_folder`, `get_titanic_input`)
- **Number of classes**: 0
- **Number of imports**: 14
- **Number of models trained**: 8 (Support Vector Machine, K-Nearest Neighbors, Decision Tree, Logistic Regression, Random Forest, Gradient Boosting, Neural Network (MLP), Naive Bayes)

The code performs the following tasks:
1. Imports necessary libraries.
2. Loads and preprocesses the Titanic dataset.
3. Converts categorical variables to numerical.
4. Scales the features.
5. Trains a logistic regression model and evaluates its performance.
6. Compares multiple machine learning models.
7. Saves the trained models.
8. Provides functions to load models and take user input for predictions.
